{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPhcKbjTmBXn2Pp75e+bzO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OLIVEIRA028/Projetos_ALura_/blob/main/Chat_Bot_Alura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHAT BOT üí≠"
      ],
      "metadata": {
        "id": "8jOpzuqyXLLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "14xrwvk-UkqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui importaremos a biblioteca SDK do Google\n",
        "from google import generativeai as genai\n",
        "# Usado para armazenar com seguran√ßa sua chave de API em `google.colab.userdata`\n",
        "from google.colab import userdata\n",
        "\n",
        "# Cole sua chave da API aqui\n",
        "api_key = \"COLE_SUA_CHAVE_AQUI\"\n",
        "\n",
        "# Configure a biblioteca com a chave da API\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "PsF5Wc2EXZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos da IA que est√£o disponiveis"
      ],
      "metadata": {
        "id": "0IX75L4AYeU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Este c√≥digo lista todos os modelos de IA generativa dispon√≠veis no Google\n",
        "# Cloud e imprime os nomes dos modelos que suportam o m√©todo de gera√ß√£o\n",
        "# `generateContent`.\n",
        "\n",
        "# O m√©todo `genai.list_models()` retorna uma lista de objetos `Model`. Cada\n",
        "# objeto `Model` representa um modelo de IA generativa e possui v√°rios\n",
        "# atributos, incluindo `name` e `supported_generation_methods`.\n",
        "\n",
        "# O c√≥digo itera sobre a lista de modelos e verifica se o m√©todo\n",
        "# `generateContent` est√° inclu√≠do na lista de m√©todos de gera√ß√£o suportados\n",
        "# para cada modelo. Se for, o c√≥digo imprime o nome do modelo.\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if \"generateContent\" in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "oNp1AQuDXfeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta √© uma configura√ß√£o para o m√©todo `generate_content` da biblioteca SDK\n",
        "# do Google para IA generativa. Ele especifica os seguintes par√¢metros:\n",
        "\n",
        "#* `candidate_count`: O n√∫mero de candidatos de gera√ß√£o a serem retornados.\n",
        "# Neste caso, est√° definido como 1, o que significa que apenas um candidato\n",
        "# ser√° gerado.\n",
        "\n",
        "#* `temperature`: Um valor que controla a aleatoriedade da gera√ß√£o.\n",
        "# Um valor mais alto resulta em gera√ß√µes mais criativas, mas potencialmente\n",
        "# menos coerentes. Um valor mais baixo resulta em gera√ß√µes mais previs√≠veis,\n",
        "# mas potencialmente menos interessantes. Neste caso, est√° definido como 0,5,\n",
        "# que √© um valor intermedi√°rio.\n",
        "\n",
        "#Esta configura√ß√£o pode ser usada para gerar um √∫nico candidato de gera√ß√£o com um n√≠vel moderado de aleatoriedade.\n",
        "\n",
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "imrb3vJsXhSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta √© uma configura√ß√£o para o m√©todo `generate_content` da biblioteca SDK\n",
        "# do Google para IA generativa. Ele especifica as seguintes configura√ß√µes de\n",
        "# seguran√ßa:\n",
        "\n",
        "#* `Harassment`: O n√≠vel de prote√ß√£o contra conte√∫do de ass√©dio. `Block_None` significa que nenhum conte√∫do de ass√©dio ser√° bloqueado.\n",
        "#* `Hate`: O n√≠vel de prote√ß√£o contra conte√∫do de √≥dio. `Block_None` significa que nenhum conte√∫do de √≥dio ser√° bloqueado.\n",
        "#* `Sexual`: O n√≠vel de prote√ß√£o contra conte√∫do sexual. `Block_None` significa que nenhum conte√∫do sexual ser√° bloqueado.\n",
        "#* `Dangerous`: O n√≠vel de prote√ß√£o contra conte√∫do perigoso. `Block_None` significa que nenhum conte√∫do perigoso ser√° bloqueado.\n",
        "\n",
        "#Esta configura√ß√£o permite que todo o conte√∫do seja gerado, incluindo conte√∫do que possa ser considerado ass√©dio, discurso de √≥dio, conte√∫do sexual ou perigoso.\n",
        "\n",
        "#Observe que √© importante usar as configura√ß√µes de seguran√ßa com cuidado, pois elas podem afetar a qualidade e a utilidade do conte√∫do gerado.\n",
        "\n",
        "safety_settings = {\n",
        "    \"Harassment\": \"Block_None\",\n",
        "    \"Hate\": \"Block_None\",\n",
        "    \"Sexual\": \"Block_None\",\n",
        "    \"Dangerous\": \"Block_None\",\n",
        "}"
      ],
      "metadata": {
        "id": "EEOaTCJCcuPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "NRD23IOBd2k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Este c√≥digo cria um objeto `GenerativeModel` que representa um modelo de IA\n",
        "# generativa espec√≠fico. O modelo √© especificado pelo seu nome, que neste caso\n",
        "# √© `\"gemini-1.0-pro\"`.\n",
        "\n",
        "# O objeto `GenerativeModel` tamb√©m √© configurado com as configura√ß√µes de\n",
        "# gera√ß√£o e seguran√ßa especificadas anteriormente.\n",
        "\n",
        "# Este objeto `GenerativeModel` pode ser usado para gerar conte√∫do textual\n",
        "# usando o m√©todo `generate_content`.\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "8gFp3oqQd2NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Este c√≥digo usa o objeto `GenerativeModel` para gerar conte√∫do textual com base no prompt fornecido.\n",
        "#O prompt √©: \"Vamos aprender sobre IA, me d√™ sugest√µes.\".\n",
        "\n",
        "# O m√©todo `generate_content` retorna um objeto `GenerationResponse` que\n",
        "# cont√©m o conte√∫do gerado. O conte√∫do gerado √© impresso no console usando a\n",
        "# fun√ß√£o `print`.\n",
        "\n",
        "#A sa√≠da do c√≥digo ser√° algo como o seguinte:\n",
        "\n",
        "# GenerationResponse(candidates=[Candidate(generated_content=\"* **Introdu√ß√£o\n",
        "# √† IA**\\n\\n* **O que √© IA?**\\n\\n* **Tipos de IA**\\n\\n* **Aplica√ß√µes da\n",
        "# IA**\\n\\n* **Benef√≠cios da IA**\\n\\n* **Desafios da IA**\\n\\n* **O futuro da\n",
        "# IA**\\n\\n* **Conclus√£o**\")])\n",
        "\n",
        "# Neste caso, o conte√∫do gerado √© uma lista de t√≥picos que podem ser cobertos\n",
        "# em uma introdu√ß√£o √† IA.\n",
        "\n",
        "response = model.generate_content(\"Vamos aprender sobre IA, me d√™ sugest√µes.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "BL3WQvySe4kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "USgJD1y-fRTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Este c√≥digo cria um loop interativo que permite ao usu√°rio conversar com um\n",
        "# chatbot.\n",
        "\n",
        "# O loop come√ßa solicitando ao usu√°rio que insira um prompt. O prompt √©\n",
        "# ent√£o enviado para o chatbot usando o m√©todo `send_message`.\n",
        "\n",
        "# A resposta do chatbot √© impressa no console e o usu√°rio √© solicitado a\n",
        "# inserir outro prompt.\n",
        "\n",
        "#O loop continua at√© que o usu√°rio insira o prompt \"fim\", que encerra o loop.\n",
        "\n",
        "# Este c√≥digo √© √∫til para testar um chatbot e obter uma ideia de como ele\n",
        "# responde a diferentes prompts.\n",
        "\n",
        "import os\n",
        "from tabulate import tabulate\n",
        "\n",
        "while True:\n",
        "    os.system('cls' if os.name == 'nt' else 'clear')\n",
        "\n",
        "    prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "    if prompt == \"fim\":\n",
        "        break\n",
        "\n",
        "    response = chat.send_message(prompt)\n",
        "    table = tabulate([[\"Pergunta\", \"Resposta\"], [prompt, response.text]], tablefmt=\"fancy_grid\")\n",
        "    print(table)\n",
        "\n",
        "    # Limpa o output ap√≥s cada resposta\n",
        "    os.system('cls' if os.name == 'nt' else 'clear')"
      ],
      "metadata": {
        "id": "rlzAeVCOft48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `chat` √© uma vari√°vel que representa um objeto `Conversation` da biblioteca\n",
        "# SDK do Google para IA conversacional.\n",
        "\n",
        "chat"
      ],
      "metadata": {
        "id": "u2faz4IlmQyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Isso imprimir√° o hist√≥rico da conversa no console.\n",
        "\n",
        "# Voc√™ tamb√©m pode usar o hist√≥rico da conversa para treinar um modelo de\n",
        "# aprendizado de m√°quina para melhorar o desempenho do chatbot. Por exemplo,\n",
        "# voc√™ pode usar o hist√≥rico da conversa para treinar um modelo de\n",
        "# classifica√ß√£o para identificar a inten√ß√£o do usu√°rio em cada mensagem.\n",
        "\n",
        "chat.history"
      ],
      "metadata": {
        "id": "C2KQ51nTmRkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Este c√≥digo melhora a visualiza√ß√£o do hist√≥rico da conversa usando as\n",
        "# seguintes t√©cnicas:\n",
        "\n",
        "#* **Substituindo marcadores por asteriscos:** Os marcadores (`‚Ä¢`) s√£o substitu√≠dos por asteriscos (`*`) para melhorar a legibilidade.\n",
        "#* **Recuo do texto:** O texto de cada mensagem √© recuado para torn√°-lo mais f√°cil de ler.\n",
        "#* **Exibi√ß√£o de Markdown:** O texto de cada mensagem √© exibido como Markdown para melhorar a formata√ß√£o.\n",
        "\n",
        "#O resultado √© um hist√≥rico de conversa mais f√°cil de ler e entender.\n",
        "\n",
        "# Este c√≥digo √© √∫til para depurar conversas com chatbots e obter uma ideia de\n",
        "# como eles est√£o respondendo √†s mensagens do usu√°rio.\n",
        "\n",
        "\n",
        "#melhorando a visualiza√ß√£o\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace(\"‚Ä¢\", \" *\")\n",
        "  return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o hist√≥rico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f\"**{message.role}**: {message.parts[0].text}\"))\n",
        "  print(\"-------------------------------------------\")"
      ],
      "metadata": {
        "id": "S4eHykNgkV-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}